<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang='en'>
<head>
<title>direct_s3.md</title>
<meta content='text/html; charset=UTF-8' http-equiv='Content-Type'>
<link href='../../css/style.css' media='screen' rel='stylesheet' type='text/css'>
<script type='text/javascript'>
  function popupCode(url) {
    window.open(url, "Code", "resizable=yes,scrollbars=yes,toolbar=no,status=no,height=150,width=400")
  }
  
  function toggleCode(id) {
    var code = document.getElementById(id)
  
    code.style.display = code.style.display != 'block' ? 'block' : 'none'
    return true
  }
  
  // Make codeblocks hidden by default
  document.writeln('<' + 'style type="text/css">.method .source pre { display: none }<\/style>')
</script>
</head>
<body class='page'>
<div class='file' id='wrapper'>
<div class='header'>
<h1 class='name'>direct_s3.md
</h1>
<div class='paths'>
doc/direct_s3.md
</div>
<div class='last-update'>
Last Update:
<span class='datetime'>2018-07-10 13:38:52 +0200</span>
</div>
</div>
<div id='content'>
<div id='text'>
<div id='description'>
<h1 id="label-Direct+Uploads+to+S3">Direct Uploads to S3<span><a href="#label-Direct+Uploads+to+S3">&para;</a> <a href="#top">&uarr;</a></span></h1>

<p><a href="../../classes/Shrine.html">Shrine</a> gives you the ability to
upload files directly to Amazon S3 (or any other storage service that
accepts direct uploads). Uploading directly to a storage service is
beneficial for several reasons:</p>
<ul><li>
<p>Accepting uploads is resource-intensive for the server, and delegating it
to  an external service makes scaling easier.</p>
</li><li>
<p>If both temporary and permanent storage are S3, promoting an S3 file to 
permanent storage will simply issue an S3 copy request, without any 
downloading and reuploading.</p>
</li><li>
<p>With multiple servers it&#39;s generally not possible to cache files to the
disk,  unless you&#39;re using a distibuted filesystem that&#39;s shared
between servers.</p>
</li><li>
<p>On Heroku any uploaded files that aren&#39;t part of version control
don&#39;t persist,  they get removed each time you do a new deploy or when
the dyno automatically  changes the location.</p>
</li><li>
<p>If your request workers have a timeout configured or you&#39;re using
Heroku,  uploading large files to S3 or any external service inside the 
request-response lifecycle might not be able to finish before the request 
times out.</p>
</li></ul>

<p>To start, let&#39;s set both temporary and permanent storage to S3, with
the temporary storage uploading to the <code>cache/</code> directory:</p>

<pre class="ruby"><span class="ruby-comment"># Gemfile</span>&#x000A;<span class="ruby-identifier">gem</span> <span class="ruby-string">&quot;shrine&quot;</span>, <span class="ruby-string">&quot;~&gt; 2.11&quot;</span>&#x000A;<span class="ruby-identifier">gem</span> <span class="ruby-string">&quot;aws-sdk-s3&quot;</span>, <span class="ruby-string">&quot;~&gt; 1.2&quot;</span></pre>

<pre class="ruby"><span class="ruby-identifier">require</span> <span class="ruby-string">&quot;shrine/storage/s3&quot;</span>&#x000A;&#x000A;<span class="ruby-identifier">s3_options</span> = {&#x000A;  <span class="ruby-value">bucket:</span>            <span class="ruby-string">&quot;&lt;YOUR BUCKET&gt;&quot;</span>, <span class="ruby-comment"># required</span>&#x000A;  <span class="ruby-value">access_key_id:</span>     <span class="ruby-string">&quot;&lt;YOUR KEY&gt;&quot;</span>,&#x000A;  <span class="ruby-value">secret_access_key:</span> <span class="ruby-string">&quot;&lt;YOUR SECRET&gt;&quot;</span>,&#x000A;  <span class="ruby-value">region:</span>            <span class="ruby-string">&quot;&lt;REGION&gt;&quot;</span>,&#x000A;}&#x000A;&#x000A;<span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">storages</span> = {&#x000A;  <span class="ruby-value">cache:</span> <span class="ruby-constant">Shrine</span><span class="ruby-operator">::</span><span class="ruby-constant">Storage</span><span class="ruby-operator">::</span><span class="ruby-constant">S3</span>.<span class="ruby-identifier">new</span>(<span class="ruby-value">prefix:</span> <span class="ruby-string">&quot;cache&quot;</span>, <span class="ruby-operator">**</span><span class="ruby-identifier">s3_options</span>),&#x000A;  <span class="ruby-value">store:</span> <span class="ruby-constant">Shrine</span><span class="ruby-operator">::</span><span class="ruby-constant">Storage</span><span class="ruby-operator">::</span><span class="ruby-constant">S3</span>.<span class="ruby-identifier">new</span>(<span class="ruby-operator">**</span><span class="ruby-identifier">s3_options</span>),&#x000A;}</pre>

<h2 id="label-Enabling+CORS">Enabling CORS<span><a href="#label-Enabling+CORS">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>In order to be able upload files directly to your S3 bucket, you need
enable CORS. You can do that from the AWS S3 Console by going to your
bucket, clicking on the “Permissions” tab, then on “CORS Configuration”,
and following the <a
href="http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html">guide for
configuring CORS</a>.</p>

<p>Alternatively you can configure CORS via an <a
href="https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3/Client.html#put_bucket_cors-instance_method">API
call</a>:</p>

<pre class="ruby"><span class="ruby-identifier">require</span> <span class="ruby-string">&quot;aws-sdk-s3&quot;</span>&#x000A;&#x000A;<span class="ruby-identifier">client</span> = <span class="ruby-constant">Aws</span><span class="ruby-operator">::</span><span class="ruby-constant">S3</span><span class="ruby-operator">::</span><span class="ruby-constant">Client</span>.<span class="ruby-identifier">new</span>(&#x000A;  <span class="ruby-value">access_key_id:</span>     <span class="ruby-string">&quot;&lt;YOUR KEY&gt;&quot;</span>,&#x000A;  <span class="ruby-value">secret_access_key:</span> <span class="ruby-string">&quot;&lt;YOUR SECRET&gt;&quot;</span>,&#x000A;  <span class="ruby-value">region:</span>            <span class="ruby-string">&quot;&lt;REGION&gt;&quot;</span>,&#x000A;)&#x000A;&#x000A;<span class="ruby-identifier">client</span>.<span class="ruby-identifier">put_bucket_cors</span>(&#x000A;  <span class="ruby-value">bucket:</span> <span class="ruby-string">&quot;&lt;YOUR BUCKET&gt;&quot;</span>,&#x000A;  <span class="ruby-value">cors_configuration:</span> {&#x000A;    <span class="ruby-value">cors_rules:</span> [{&#x000A;      <span class="ruby-value">allowed_headers:</span> [<span class="ruby-string">&quot;Authorization&quot;</span>, <span class="ruby-string">&quot;Content-Type&quot;</span>, <span class="ruby-string">&quot;Origin&quot;</span>],&#x000A;      <span class="ruby-value">allowed_methods:</span> [<span class="ruby-string">&quot;GET&quot;</span>, <span class="ruby-string">&quot;POST&quot;</span>, <span class="ruby-string">&quot;PUT&quot;</span>],&#x000A;      <span class="ruby-value">allowed_origins:</span> [<span class="ruby-string">&quot;*&quot;</span>],&#x000A;      <span class="ruby-value">max_age_seconds:</span> <span class="ruby-value">3000</span>,&#x000A;    }]&#x000A;  }&#x000A;)</pre>

<p>Note that due to DNS propagation it may take some time for the CORS update
to be applied.</p>

<h2 id="label-Strategy+A+-28dynamic-29">Strategy A (dynamic)<span><a href="#label-Strategy+A+-28dynamic-29">&para;</a> <a href="#top">&uarr;</a></span></h2>
<ul><li>
<p>Best user experience</p>
</li><li>
<p>Single or multiple file uploads</p>
</li><li>
<p>Some JavaScript needed</p>
</li></ul>

<p>When the user selects a file in the form, on the client-side we
asynchronously fetch the presign information from the server, and use this
information to upload the file to S3. The <code>presign_endpoint</code>
plugin gives us this presign route, so we just need to mount it in our
application:</p>

<pre class="ruby"><span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">plugin</span> <span class="ruby-value">:presign_endpoint</span>, <span class="ruby-value">presign_options:</span> { <span class="ruby-value">method:</span> <span class="ruby-value">:put</span> }</pre>

<pre class="ruby"><span class="ruby-comment"># config.ru (Rack)</span>&#x000A;<span class="ruby-identifier">map</span> <span class="ruby-string">&quot;/presign&quot;</span> <span class="ruby-keyword">do</span>&#x000A;  <span class="ruby-identifier">run</span> <span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">presign_endpoint</span>(<span class="ruby-value">:cache</span>)&#x000A;<span class="ruby-keyword">end</span>&#x000A;&#x000A;<span class="ruby-comment"># OR</span>&#x000A;&#x000A;<span class="ruby-comment"># config/routes.rb (Rails)</span>&#x000A;<span class="ruby-constant">Rails</span>.<span class="ruby-identifier">application</span>.<span class="ruby-identifier">routes</span>.<span class="ruby-identifier">draw</span> <span class="ruby-keyword">do</span>&#x000A;  <span class="ruby-identifier">mount</span> <span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">presign_endpoint</span>(<span class="ruby-value">:cache</span>) <span class="ruby-operator">=&gt;</span> <span class="ruby-string">&quot;/presign&quot;</span>&#x000A;<span class="ruby-keyword">end</span></pre>

<p>The above will create a <code>GET /presign</code> route, which internally
calls <a
href="https://shrinerb.com/rdoc/classes/Shrine/Storage/S3.html#method-i-presign">Shrine::Storage::S3#presign</a>,
returning the HTTP verb (PUT) and the S3 URL to which the file should be
uploaded, along with the required parameters (will only be present for POST
presigns) and request headers.</p>

<pre class="ruby"><span class="ruby-comment"># GET /presign</span>&#x000A;{&#x000A;  <span class="ruby-value">&quot;method&quot;:</span> <span class="ruby-string">&quot;put&quot;</span>,&#x000A;  <span class="ruby-value">&quot;url&quot;:</span> <span class="ruby-string">&quot;https://my-bucket.s3.eu-central-1.amazonaws.com/cache/my-key?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIMDH2HTSB3RKB4WQ%2F20180424%2Feu-central-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20180424T212022Z&amp;X-Amz-Expires=900&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=1036b9cefe52f0b46c1f257f6817fc3c55cd8d9004f87a38cf86177762359375&quot;</span>,&#x000A;  <span class="ruby-value">&quot;fields&quot;:</span> {},&#x000A;  <span class="ruby-value">&quot;headers&quot;:</span> {}&#x000A;}</pre>

<p>On the client side you can make it so that, when the user selects a file,
upload parameters are fetched from presign endpoint, and are used to upload
the selected file directly to S3. It&#39;s recommended to use <a
href="https://uppy.io">Uppy</a> for this.</p>

<p>Once the file has been uploaded, you can generate a JSON representation of
the uploaded file on the client-side, and write it to the hidden attachment
field (or send it directly in an AJAX request).</p>

<pre class="ruby">{&#x000A;  <span class="ruby-value">&quot;id&quot;:</span> <span class="ruby-string">&quot;302858ldg9agjad7f3ls.jpg&quot;</span>,&#x000A;  <span class="ruby-value">&quot;storage&quot;:</span> <span class="ruby-string">&quot;cache&quot;</span>,&#x000A;  <span class="ruby-value">&quot;metadata&quot;:</span> {&#x000A;    <span class="ruby-value">&quot;size&quot;:</span> <span class="ruby-value">943483</span>,&#x000A;    <span class="ruby-value">&quot;filename&quot;:</span> <span class="ruby-string">&quot;nature.jpg&quot;</span>,&#x000A;    <span class="ruby-value">&quot;mime_type&quot;:</span> <span class="ruby-string">&quot;image/jpeg&quot;</span>,&#x000A;  }&#x000A;}</pre>
<ul><li>
<p><code>id</code> – location of the file on S3 (minus the
<code>:prefix</code>)</p>
</li><li>
<p><code>storage</code> – direct uploads typically use the <code>:cache</code>
storage</p>
</li><li>
<p><code>metadata</code> – hash of metadata extracted from the file</p>
</li></ul>

<p>Once submitted this JSON will then be assigned to the attachment attribute
instead of the raw file. See <a
href="https://github.com/shrinerb/shrine/wiki/Adding-Direct-S3-Uploads">this
walkthrough</a> for adding dynamic direct S3 uploads from scratch using <a
href="https://uppy.io">Uppy</a>, as well as the <a
href="https://github.com/shrinerb/shrine/tree/master/demo">Roda</a> or <a
href="https://github.com/erikdahlstrand/shrine-rails-example">Rails</a>
demo app for a complete example of multiple direct S3 uploads.</p>

<h2 id="label-Strategy+B+-28static-29">Strategy B (static)<span><a href="#label-Strategy+B+-28static-29">&para;</a> <a href="#top">&uarr;</a></span></h2>
<ul><li>
<p>Basic user experience</p>
</li><li>
<p>Only for single uploads</p>
</li><li>
<p>No JavaScript needed</p>
</li></ul>

<p>An alternative to the previous strategy is to generate an S3 upload form on
page render. The user can then select a file and submit it directly to S3.
For generating the form can use <a
href="https://shrinerb.com/rdoc/classes/Shrine/Storage/S3.html#method-i-presign">Shrine::Storage::S3#presign</a>,
which returns URL and form fields that should be used for the upload.</p>

<pre class="ruby"><span class="ruby-identifier">presigned_data</span> = <span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">storages</span>[<span class="ruby-value">:cache</span>].<span class="ruby-identifier">presign</span>(&#x000A;  <span class="ruby-constant">SecureRandom</span>.<span class="ruby-identifier">hex</span>,&#x000A;  <span class="ruby-value">success_action_redirect:</span> <span class="ruby-identifier">new_album_url</span>&#x000A;)&#x000A;&#x000A;<span class="ruby-identifier">form</span> <span class="ruby-value">action:</span> <span class="ruby-identifier">presigned_data</span>[<span class="ruby-value">:url</span>], <span class="ruby-value">method:</span> <span class="ruby-string">&quot;post&quot;</span>, <span class="ruby-value">enctype:</span> <span class="ruby-string">&quot;multipart/form-data&quot;</span> <span class="ruby-keyword">do</span> <span class="ruby-operator">|</span><span class="ruby-identifier">f</span><span class="ruby-operator">|</span>&#x000A;  <span class="ruby-identifier">presigned_data</span>[<span class="ruby-value">:fields</span>].<span class="ruby-identifier">each</span> <span class="ruby-keyword">do</span> <span class="ruby-operator">|</span><span class="ruby-identifier">name</span>, <span class="ruby-identifier">value</span><span class="ruby-operator">|</span>&#x000A;    <span class="ruby-identifier">f</span>.<span class="ruby-identifier">input</span> <span class="ruby-value">:hidden</span>, <span class="ruby-value">name:</span> <span class="ruby-identifier">name</span>, <span class="ruby-value">value:</span> <span class="ruby-identifier">value</span>&#x000A;  <span class="ruby-keyword">end</span>&#x000A;  <span class="ruby-identifier">f</span>.<span class="ruby-identifier">input</span> <span class="ruby-value">:file</span>, <span class="ruby-value">name:</span> <span class="ruby-string">&quot;file&quot;</span>&#x000A;  <span class="ruby-identifier">f</span>.<span class="ruby-identifier">button</span> <span class="ruby-string">&quot;Submit&quot;</span>&#x000A;<span class="ruby-keyword">end</span></pre>

<p>Note the additional <code>:success_action_redirect</code> option which
tells S3 where to redirect to after the file has been uploaded. If
you&#39;re using the Rails form builder to generate this form, you might
need to also tell S3 to ignore the additional <code>utf8</code> and
<code>authenticity_token</code> fields that Rails generates:</p>

<pre class="ruby"><span class="ruby-identifier">presigned_data</span> = <span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">storages</span>[<span class="ruby-value">:cache</span>].<span class="ruby-identifier">presign</span>(&#x000A;  <span class="ruby-constant">SecureRandom</span>.<span class="ruby-identifier">hex</span>,&#x000A;  <span class="ruby-value">allow_any:</span> [<span class="ruby-string">&quot;utf8&quot;</span>, <span class="ruby-string">&quot;authenticity_token&quot;</span>],&#x000A;  <span class="ruby-value">success_action_redirect:</span> <span class="ruby-identifier">new_album_url</span>&#x000A;)&#x000A;&#x000A;<span class="ruby-comment"># ...</span></pre>

<p>Let&#39;s assume we specified the redirect URL to be a page which renders
the form for a new record. S3 will include some information about the
upload in form of GET parameters in the URL, out of which we only need the
<code>key</code> parameter:</p>

<pre class="ruby"><span class="ruby-identifier">cached_file</span> = {&#x000A;  <span class="ruby-value">storage:</span> <span class="ruby-string">&quot;cache&quot;</span>,&#x000A;  <span class="ruby-value">id:</span> <span class="ruby-identifier">request</span>.<span class="ruby-identifier">params</span>[<span class="ruby-value">:key</span>][<span class="ruby-regexp">/cache\/(.+)/</span>, <span class="ruby-value">1</span>], <span class="ruby-comment"># we subtract the storage prefix</span>&#x000A;  <span class="ruby-value">metadata:</span> {},&#x000A;}&#x000A;&#x000A;<span class="ruby-identifier">form</span> <span class="ruby-ivar">@album</span>, <span class="ruby-value">action:</span> <span class="ruby-string">&quot;/albums&quot;</span> <span class="ruby-keyword">do</span> <span class="ruby-operator">|</span><span class="ruby-identifier">f</span><span class="ruby-operator">|</span>&#x000A;  <span class="ruby-identifier">f</span>.<span class="ruby-identifier">input</span> <span class="ruby-value">:image</span>, <span class="ruby-value">type:</span> <span class="ruby-value">:hidden</span>, <span class="ruby-value">value:</span> <span class="ruby-identifier">cached_file</span>.<span class="ruby-identifier">to_json</span>&#x000A;  <span class="ruby-identifier">f</span>.<span class="ruby-identifier">button</span> <span class="ruby-string">&quot;Save&quot;</span>&#x000A;<span class="ruby-keyword">end</span></pre>

<h2 id="label-Object+data">Object data<span><a href="#label-Object+data">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>When the cached S3 object is copied to permanent storage, the destination
S3 object will by default inherit any object data that was assigned to the
cached object via presign parameters. However, S3 will by default also
ignore any new object parameters that are given to the copy request.</p>

<p>Whether object data will be copied or replaced depends on the value of the
<code>:metadata_directive</code> parameter:</p>
<ul><li>
<p><code>&quot;COPY&quot;</code> - destination object will inherit source
object data and any new data will be ignored (default)</p>
</li><li>
<p><code>&quot;REPLACE&quot;</code> - destination object will not inherit any
of the source object data and will accept new data</p>
</li></ul>

<p>You can use the <code>upload_options</code> plugin to change the
<code>:metadata_directive</code> option when S3 objects are copied:</p>

<pre class="ruby"><span class="ruby-identifier">plugin</span> <span class="ruby-value">:upload_options</span>, <span class="ruby-value">store:</span> <span class="ruby-operator">-&gt;</span> (<span class="ruby-identifier">io</span>, <span class="ruby-identifier">context</span>) <span class="ruby-keyword">do</span>&#x000A;  { <span class="ruby-value">metadata_directive:</span> <span class="ruby-string">&quot;REPLACE&quot;</span> } <span class="ruby-keyword">if</span> <span class="ruby-identifier">io</span>.<span class="ruby-identifier">is_a?</span>(<span class="ruby-constant">Shrine</span><span class="ruby-operator">::</span><span class="ruby-constant">UploadedFile</span>)&#x000A;<span class="ruby-keyword">end</span></pre>

<h2 id="label-Shrine+metadata"><a href="../../classes/Shrine.html">Shrine</a> metadata<span><a href="#label-Shrine+metadata">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>With direct uploads any metadata has to be extracted on the client-side,
since the file upload doesn&#39;t touch the application, so the <a
href="../../classes/Shrine.html">Shrine</a> uploader doesn&#39;t get a
chance to extract the metadata. When directly uploaded file is promoted to
permanent storage, Shrine&#39;s default behaviour is to just copy the
received metadata.</p>

<p>If you want to re-extract metadata on the server before file validation,
you can load the <code>restore_cached_data</code>. That will make <a
href="../../classes/Shrine.html">Shrine</a> open the S3 file for reading,
pass it for metadata extraction, and then override the metadata received
from the client with the extracted ones.</p>

<pre class="ruby"><span class="ruby-identifier">plugin</span> <span class="ruby-value">:restore_cached_data</span></pre>

<p>Note that if you don&#39;t need this metadata before file validation, and
you would like to have it extracted in a background job, you can do that
with the following trick:</p>

<pre class="ruby"><span class="ruby-keyword">class</span> <span class="ruby-constant">MyUploader</span> <span class="ruby-operator">&lt;</span> <span class="ruby-constant">Shrine</span>&#x000A;  <span class="ruby-identifier">plugin</span> <span class="ruby-value">:processing</span>&#x000A;  <span class="ruby-identifier">plugin</span> <span class="ruby-value">:refresh_metadata</span>&#x000A;&#x000A;  <span class="ruby-identifier">process</span>(<span class="ruby-value">:store</span>) <span class="ruby-keyword">do</span> <span class="ruby-operator">|</span><span class="ruby-identifier">io</span>, <span class="ruby-identifier">context</span><span class="ruby-operator">|</span>&#x000A;    <span class="ruby-identifier">io</span>.<span class="ruby-identifier">refresh_metadata!</span>&#x000A;    <span class="ruby-identifier">io</span> <span class="ruby-comment"># return the same cached IO</span>&#x000A;  <span class="ruby-keyword">end</span>&#x000A;<span class="ruby-keyword">end</span></pre>

<h2 id="label-Checksum">Checksum<span><a href="#label-Checksum">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>To have AWS S3 verify the integrity of the uploaded data, you can use a
checksum. For that you first need to tell AWS S3 that you&#39;re going to
be including the <code>Content-MD5</code> request header in the upload
request, by adding the <code>:content_md5</code> presign option.</p>

<pre class="ruby"><span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">plugin</span> <span class="ruby-value">:presign_endpoint</span>, <span class="ruby-value">presign_options:</span> <span class="ruby-operator">-&gt;</span> (<span class="ruby-identifier">request</span>) <span class="ruby-keyword">do</span>&#x000A;  {&#x000A;    <span class="ruby-value">content_md5:</span> <span class="ruby-identifier">request</span>.<span class="ruby-identifier">params</span>[<span class="ruby-string">&quot;checksum&quot;</span>],&#x000A;    <span class="ruby-value">method:</span> <span class="ruby-value">:put</span>,&#x000A;  }&#x000A;<span class="ruby-keyword">end</span></pre>

<p>With the above setup, you can pass the MD5 hash of the file via the
<code>checksum</code> query parameter in the request to the presign
endpoint. See <a
href="https://github.com/shrinerb/shrine/wiki/Using-Checksums-in-Direct-Uploads">this
walkthrough</a> for a complete JavaScript solution.</p>

<h2 id="label-Clearing+cache">Clearing cache<span><a href="#label-Clearing+cache">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>Directly uploaded files won&#39;t automatically be deleted from your
temporary storage, so you&#39;ll want to periodically clear them. One way
to do that is by setting up recurring script which calls
<code>Shrine::Storage::S3#clear!</code>:</p>

<pre class="ruby"><span class="ruby-identifier">s3</span> = <span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">storages</span>[<span class="ruby-value">:cache</span>]&#x000A;<span class="ruby-identifier">s3</span>.<span class="ruby-identifier">clear!</span> { <span class="ruby-operator">|</span><span class="ruby-identifier">object</span><span class="ruby-operator">|</span> <span class="ruby-identifier">object</span>.<span class="ruby-identifier">last_modified</span> <span class="ruby-operator">&lt;</span> <span class="ruby-constant">Time</span>.<span class="ruby-identifier">now</span> <span class="ruby-operator">-</span> <span class="ruby-value">7</span><span class="ruby-operator">*</span><span class="ruby-value">24</span><span class="ruby-operator">*</span><span class="ruby-value">60</span><span class="ruby-operator">*</span><span class="ruby-value">60</span> } <span class="ruby-comment"># delete files older than 1 week</span></pre>

<p>Alternatively you can add a bucket lifeycle rule to do this for you. This
can be done either from the <a
href="http://docs.aws.amazon.com/AmazonS3/latest/UG/lifecycle-configuration-bucket-no-versioning.html">AWS
Console</a> or via an <a
href="https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3/Client.html#put_bucket_lifecycle_configuration-instance_method">API
call</a>:</p>

<pre class="ruby"><span class="ruby-identifier">require</span> <span class="ruby-string">&quot;aws-sdk-s3&quot;</span>&#x000A;&#x000A;<span class="ruby-identifier">client</span> = <span class="ruby-constant">Aws</span><span class="ruby-operator">::</span><span class="ruby-constant">S3</span><span class="ruby-operator">::</span><span class="ruby-constant">Client</span>.<span class="ruby-identifier">new</span>(&#x000A;  <span class="ruby-value">access_key_id:</span>     <span class="ruby-string">&quot;&lt;YOUR KEY&gt;&quot;</span>,&#x000A;  <span class="ruby-value">secret_access_key:</span> <span class="ruby-string">&quot;&lt;YOUR SECRET&gt;&quot;</span>,&#x000A;  <span class="ruby-value">region:</span>            <span class="ruby-string">&quot;&lt;REGION&gt;&quot;</span>,&#x000A;)&#x000A;&#x000A;<span class="ruby-identifier">client</span>.<span class="ruby-identifier">put_bucket_lifecycle_configuration</span>(&#x000A;  <span class="ruby-value">bucket:</span> <span class="ruby-string">&quot;&lt;YOUR BUCKET&gt;&quot;</span>,&#x000A;  <span class="ruby-value">lifecycle_configuration:</span> {&#x000A;    <span class="ruby-value">rules:</span> [{&#x000A;      <span class="ruby-value">expiration:</span> { <span class="ruby-value">days:</span> <span class="ruby-value">7</span> },&#x000A;      <span class="ruby-value">filter:</span> { <span class="ruby-value">prefix:</span> <span class="ruby-string">&quot;cache/&quot;</span> },&#x000A;      <span class="ruby-value">id:</span> <span class="ruby-string">&quot;cache-clear&quot;</span>,&#x000A;      <span class="ruby-value">status:</span> <span class="ruby-string">&quot;Enabled&quot;</span>&#x000A;    }]&#x000A;  }&#x000A;)</pre>

<h2 id="label-Eventual+consistency">Eventual consistency<span><a href="#label-Eventual+consistency">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>When uploading objects to Amazon S3, sometimes they may not be available
immediately. This can be a problem when using direct S3 uploads, because
usually in this case you&#39;re using S3 for both cache and store, so the
S3 object is moved to store soon after caching.</p>

<blockquote>
<p>Amazon S3 provides eventual consistency for some operations, so it is
possible that new data will not be available immediately after the upload,
which could result in an incomplete data load or loading stale data. COPY
operations where the cluster and the bucket are in different regions are
eventually consistent. All regions provide read-after-write consistency for
uploads of new objects with unique object keys. For more information about
data consistency, see <a
href="http://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyMode">Amazon
S3 Data Consistency Model</a> in the <em>Amazon Simple Storage Service
Developer Guide</em>.</p>
</blockquote>

<p>This means that in certain cases copying from cache to store can fail if it
happens immediately after uploading to cache. If you start noticing these
errors, and you&#39;re using <code>backgrounding</code> plugin, you can
tell your backgrounding library to perform the job with a delay:</p>

<pre class="ruby"><span class="ruby-constant">Shrine</span>.<span class="ruby-identifier">plugin</span> <span class="ruby-value">:backgrounding</span>&#x000A;&#x000A;<span class="ruby-constant">Shrine</span><span class="ruby-operator">::</span><span class="ruby-constant">Attacher</span>.<span class="ruby-identifier">promote</span> <span class="ruby-keyword">do</span> <span class="ruby-operator">|</span><span class="ruby-identifier">data</span><span class="ruby-operator">|</span>&#x000A;  <span class="ruby-constant">PromoteJob</span>.<span class="ruby-identifier">perform_in</span>(<span class="ruby-value">3</span>, <span class="ruby-identifier">data</span>) <span class="ruby-comment"># tells a Sidekiq worker to perform in 3 seconds</span>&#x000A;<span class="ruby-keyword">end</span></pre>

<h2 id="label-Testing">Testing<span><a href="#label-Testing">&para;</a> <a href="#top">&uarr;</a></span></h2>

<p>To avoid network requests in your test and development environment, you can
use <a href="https://minio.io">Minio</a>. Minio is an open source object
storage server with AWS S3 compatible API which you can run locally. See
how to set it up in the <a
href="https://shrinerb.com/rdoc/files/doc/testing_md.html#label-Minio">Testing</a>
guide.</p>
</div>
<div id='context'>
</div>

</div>
</div>

<div id='footer-push'></div>
</div>
<div id='footer'>
<a href="https://github.com/rdoc/hanna-nouveau"><strong>Hanna Nouveau</strong> RDoc template</a>
</div>
</body>
</html>
